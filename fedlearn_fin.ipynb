{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T12:58:56.224249Z",
     "iopub.status.busy": "2025-04-15T12:58:56.223772Z",
     "iopub.status.idle": "2025-04-15T12:59:10.753068Z",
     "shell.execute_reply": "2025-04-15T12:59:10.752336Z",
     "shell.execute_reply.started": "2025-04-15T12:58:56.224217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 12:59:00.148576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744721940.359098      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744721940.416659      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import flwr as fl\n",
    "from flwr.common import FitIns, EvaluateIns, Parameters, NDArrays\n",
    "import logging\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T12:59:24.747313Z",
     "iopub.status.busy": "2025-04-15T12:59:24.746921Z",
     "iopub.status.idle": "2025-04-15T12:59:24.799395Z",
     "shell.execute_reply": "2025-04-15T12:59:24.798667Z",
     "shell.execute_reply.started": "2025-04-15T12:59:24.747284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-02 15:31:58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Food</td>\n",
       "      <td>Issue law fear fine economic smile.</td>\n",
       "      <td>Allow always this.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-17 11:26:05</td>\n",
       "      <td>66.76</td>\n",
       "      <td>Food</td>\n",
       "      <td>Trade type training hand effect.</td>\n",
       "      <td>Finally focus own.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-21 13:51:04</td>\n",
       "      <td>99.78</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Glass strategy woman whether bank weight.</td>\n",
       "      <td>Mind mission.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-08 07:12:18</td>\n",
       "      <td>77.10</td>\n",
       "      <td>Food</td>\n",
       "      <td>Will structure sport growth.</td>\n",
       "      <td>Many analysis begin.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-19 12:21:34</td>\n",
       "      <td>70.28</td>\n",
       "      <td>Transport</td>\n",
       "      <td>Opportunity ago wish partner behind.</td>\n",
       "      <td>Some beautiful read.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  amount   category  \\\n",
       "0  2025-02-02 15:31:58    0.44       Food   \n",
       "1  2023-08-17 11:26:05   66.76       Food   \n",
       "2  2024-07-21 13:51:04   99.78   Shopping   \n",
       "3  2024-09-08 07:12:18   77.10       Food   \n",
       "4  2020-04-19 12:21:34   70.28  Transport   \n",
       "\n",
       "                                 description     clean_description  is_fraud  \n",
       "0        Issue law fear fine economic smile.    Allow always this.         0  \n",
       "1           Trade type training hand effect.    Finally focus own.         0  \n",
       "2  Glass strategy woman whether bank weight.         Mind mission.         0  \n",
       "3               Will structure sport growth.  Many analysis begin.         0  \n",
       "4       Opportunity ago wish partner behind.  Some beautiful read.         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv\n",
    "df = pd.read_csv(r'./transactions_data_extended.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T12:59:37.999495Z",
     "iopub.status.busy": "2025-04-15T12:59:37.999217Z",
     "iopub.status.idle": "2025-04-15T12:59:38.005233Z",
     "shell.execute_reply": "2025-04-15T12:59:38.004492Z",
     "shell.execute_reply.started": "2025-04-15T12:59:37.999475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "def create_synthetic_data(num_samples: int = 1000) -> pd.DataFrame:\n",
    "    try:\n",
    "        np.random.seed(42)\n",
    "        dates = pd.date_range(start='2023-01-01', periods=num_samples)\n",
    "        amounts = np.random.exponential(scale=100, size=num_samples)\n",
    "        categories = np.random.choice(\n",
    "            ['grocery', 'utilities', 'entertainment', 'travel', 'healthcare', 'other'],\n",
    "            size=num_samples\n",
    "        )\n",
    "        descriptions = [f\"Transaction {i}\" for i in range(num_samples)]\n",
    "        clean_descriptions = [f\"Clean {desc}\" for desc in descriptions]\n",
    "        is_fraud = np.random.choice([0, 1], size=num_samples, p=[0.95, 0.05])\n",
    "        df = pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'amount': amounts,\n",
    "            'category': categories,\n",
    "            'description': descriptions,\n",
    "            'clean_description': clean_descriptions,\n",
    "            'is_fraud': is_fraud\n",
    "        })\n",
    "        logger.info(\"Synthetic data created successfully\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Synthetic data creation failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T12:59:48.629857Z",
     "iopub.status.busy": "2025-04-15T12:59:48.628933Z",
     "iopub.status.idle": "2025-04-15T12:59:48.641212Z",
     "shell.execute_reply": "2025-04-15T12:59:48.640391Z",
     "shell.execute_reply.started": "2025-04-15T12:59:48.629831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, LabelEncoder]]:\n",
    "    try:\n",
    "        def parse_date(date_str):\n",
    "            try:\n",
    "                for fmt in [\"%Y-%m-%d %H:%M:%S\", \"%d-%m-%Y\", \"%Y-%m-%d\"]:\n",
    "                    try:\n",
    "                        return datetime.strptime(str(date_str).split()[0], fmt)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                return pd.NaT\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Date parsing error: {e}\")\n",
    "                return pd.NaT\n",
    "\n",
    "        df['date'] = df['date'].apply(parse_date)\n",
    "        df = df.dropna(subset=['date'])\n",
    "\n",
    "        df['day'] = df['date'].dt.day\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['day_of_week'] = df['date'].dt.dayofweek\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "        df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "        df['is_month_start'] = df['day'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "        df['is_month_end'] = df['day'].apply(lambda x: 1 if x >= 25 else 0)\n",
    "\n",
    "        if 'amount' in df.columns:\n",
    "            df['amount_log'] = np.log1p(df['amount'].abs())\n",
    "            df['is_large_amount'] = df['amount'].apply(lambda x: 1 if x > df['amount'].quantile(0.75) else 0)\n",
    "            df['is_very_large_amount'] = df['amount'].apply(lambda x: 1 if x > df['amount'].quantile(0.95) else 0)\n",
    "\n",
    "        label_encoders = {}\n",
    "        for col in ['description', 'category', 'clean_description']:\n",
    "            if col in df.columns:\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col].astype(str))\n",
    "                label_encoders[col] = le\n",
    "\n",
    "        numerical_features = ['amount', 'amount_log', 'day', 'month', 'year', 'day_of_week', 'quarter', 'week_of_year']\n",
    "        numerical_features = [f for f in numerical_features if f in df.columns]\n",
    "        if numerical_features:\n",
    "            scaler = StandardScaler()\n",
    "            df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "        logger.info(f\"Dataset shape: {df.shape}\")\n",
    "        if 'category' in df.columns:\n",
    "            logger.info(f\"Number of categories: {df['category'].nunique()}\")\n",
    "\n",
    "        return df, label_encoders\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Preprocessing failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T12:59:59.662727Z",
     "iopub.status.busy": "2025-04-15T12:59:59.661985Z",
     "iopub.status.idle": "2025-04-15T12:59:59.671812Z",
     "shell.execute_reply": "2025-04-15T12:59:59.671121Z",
     "shell.execute_reply.started": "2025-04-15T12:59:59.662702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare datasets for each model\n",
    "def prepare_model_datasets(df: pd.DataFrame) -> Dict[str, Tuple[pd.DataFrame, pd.Series]]:\n",
    "    try:\n",
    "        base_features = ['day', 'month', 'year', 'day_of_week', 'is_weekend', 'is_month_start', \n",
    "                         'is_month_end', 'quarter', 'week_of_year']\n",
    "        amount_features = ['amount', 'amount_log', 'is_large_amount']\n",
    "\n",
    "        fraud_df = df.copy()\n",
    "        fraud_df['is_fraud'] = fraud_df.get('is_fraud', fraud_df['is_very_large_amount'])\n",
    "        fraud_features = amount_features + ['is_very_large_amount'] + base_features\n",
    "        if 'category' in df.columns:\n",
    "            fraud_features.append('category')\n",
    "        if 'clean_description' in df.columns:\n",
    "            fraud_features.append('clean_description')\n",
    "        fraud_features = [f for f in fraud_features if f in df.columns]\n",
    "        X_fraud = fraud_df[fraud_features]\n",
    "        y_fraud = fraud_df['is_fraud'].astype(int)\n",
    "\n",
    "        budget_df = df[df['is_fraud'] == 0] if 'is_fraud' in df.columns else df.copy()\n",
    "        budget_features = amount_features + base_features\n",
    "        budget_features = [f for f in budget_features if f in budget_df.columns]\n",
    "        X_budget = budget_df[budget_features]\n",
    "        y_budget = budget_df['category'].astype(int)\n",
    "\n",
    "        expense_df = budget_df.copy()\n",
    "        expense_features = base_features\n",
    "        if 'category' in expense_df.columns:\n",
    "            expense_features.append('category')\n",
    "        expense_features = [f for f in expense_features if f in df.columns]\n",
    "        X_expense = expense_df[expense_features]\n",
    "        y_expense = expense_df['amount_log'] if 'amount_log' in expense_df.columns else expense_df['amount']\n",
    "\n",
    "        forecast_df = df.sort_values('date').copy()\n",
    "        if 'amount' in forecast_df.columns:\n",
    "            for window in [3, 7, 14]:\n",
    "                forecast_df[f'rolling_avg_{window}'] = forecast_df['amount'].rolling(window=window).mean().fillna(0)\n",
    "                forecast_df[f'rolling_std_{window}'] = forecast_df['amount'].rolling(window=window).std().fillna(0)\n",
    "            forecast_df['amount_diff_1'] = forecast_df['amount'].diff(1).fillna(0)\n",
    "        forecast_features = base_features + [col for col in forecast_df.columns if 'rolling_' in col or 'amount_diff' in col]\n",
    "        forecast_features = [f for f in forecast_features if f in df.columns]\n",
    "        X_forecast = forecast_df[forecast_features]\n",
    "        y_forecast = forecast_df['amount_log'] if 'amount_log' in forecast_df.columns else forecast_df['amount']\n",
    "\n",
    "        return {\n",
    "            'fraud': (X_fraud, y_fraud),\n",
    "            'budget': (X_budget, y_budget),\n",
    "            'expense': (X_expense, y_expense),\n",
    "            'forecast': (X_forecast, y_forecast)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Dataset preparation failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:00:16.731853Z",
     "iopub.status.busy": "2025-04-15T13:00:16.731310Z",
     "iopub.status.idle": "2025-04-15T13:00:16.750920Z",
     "shell.execute_reply": "2025-04-15T13:00:16.750283Z",
     "shell.execute_reply.started": "2025-04-15T13:00:16.731822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom server strategy\n",
    "class BestModelStrategy(fl.server.strategy.Strategy):\n",
    "    def __init__(self, min_fit_clients: int, min_evaluate_clients: int, min_available_clients: int):\n",
    "        super().__init__()\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.current_parameters = None\n",
    "        self.best_score = float(\"-inf\")\n",
    "        self.best_parameters = None\n",
    "\n",
    "    def initialize_parameters(self, client_manager) -> Optional[Parameters]:\n",
    "        logger.info(\"Initializing parameters\")\n",
    "        return self.current_parameters\n",
    "\n",
    "    def configure_fit(self, server_round: int, parameters: Parameters, client_manager) -> List[Tuple[fl.server.client_proxy.ClientProxy, FitIns]]:\n",
    "        try:\n",
    "            sample_size = max(self.min_fit_clients, int(client_manager.num_available() * 1.0))\n",
    "            clients = client_manager.sample(num_clients=sample_size, min_num_clients=self.min_fit_clients)\n",
    "            config = {}\n",
    "            fit_ins = FitIns(parameters or [], config)\n",
    "            logger.info(f\"Round {server_round}: Configured fit for {len(clients)} clients\")\n",
    "            return [(client, fit_ins) for client in clients]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Configure fit failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def aggregate_fit(self, server_round: int, results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]], failures: List) -> Tuple[Optional[Parameters], Dict]:\n",
    "        try:\n",
    "            if not results or failures:\n",
    "                logger.warning(f\"Round {server_round}: No results or failures detected: {failures}\")\n",
    "                return None, {}\n",
    "            classifier_results = [(r, r.num_examples) for _, r in results if r.metrics.get(\"model_type\") in [\"fraud\", \"budget\"] and r.num_examples > 0]\n",
    "            regressor_results = [(r, r.num_examples) for _, r in results if r.metrics.get(\"model_type\") in [\"expense\", \"forecast\"] and r.num_examples > 0]\n",
    "            best_round_score = float(\"-inf\")\n",
    "            best_round_parameters = None\n",
    "            for _, fit_res in classifier_results:\n",
    "                if \"train_score\" in fit_res.metrics:\n",
    "                    score = fit_res.metrics[\"train_score\"]\n",
    "                    if score > best_round_score:\n",
    "                        best_round_score = score\n",
    "                        best_round_parameters = fit_res.parameters\n",
    "                        logger.info(f\"Round {server_round}: Classifier score={score}, model_type={fit_res.metrics.get('model_type')}\")\n",
    "            for _, fit_res in regressor_results:\n",
    "                if \"train_score\" in fit_res.metrics:\n",
    "                    mse = -fit_res.metrics[\"train_score\"]\n",
    "                    score = 1.0 / (1.0 + mse) if mse >= 0 else 0.0\n",
    "                    if score > best_round_score:\n",
    "                        best_round_score = score\n",
    "                        best_round_parameters = fit_res.parameters\n",
    "                        logger.info(f\"Round {server_round}: Regressor score={score}, raw_mse={mse}, model_type={fit_res.metrics.get('model_type')}\")\n",
    "            if best_round_score > self.best_score:\n",
    "                self.best_score = best_round_score\n",
    "                self.best_parameters = best_round_parameters\n",
    "            self.current_parameters = best_round_parameters or self.current_parameters\n",
    "            metrics = {\"best_score\": best_round_score if best_round_score != float(\"-inf\") else 0.0}\n",
    "            logger.info(f\"Round {server_round}: Aggregated fit, best score={best_round_score}\")\n",
    "            return self.current_parameters, metrics\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Round {server_round}: Aggregate fit failed: {e}\")\n",
    "            return None, {}\n",
    "\n",
    "    def configure_evaluate(self, server_round: int, parameters: Parameters, client_manager) -> List[Tuple[fl.server.client_proxy.ClientProxy, EvaluateIns]]:\n",
    "        try:\n",
    "            sample_size = max(self.min_evaluate_clients, int(client_manager.num_available() * 1.0))\n",
    "            clients = client_manager.sample(num_clients=sample_size, min_num_clients=self.min_evaluate_clients)\n",
    "            config = {}\n",
    "            evaluate_ins = EvaluateIns(parameters or [], config)\n",
    "            logger.info(f\"Round {server_round}: Configured evaluate for {len(clients)} clients\")\n",
    "            return [(client, evaluate_ins) for client in clients]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Configure evaluate failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def aggregate_evaluate(self, server_round: int, results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.EvaluateRes]], failures: List) -> Tuple[Optional[float], Dict]:\n",
    "        try:\n",
    "            if not results or failures:\n",
    "                logger.warning(f\"Round {server_round}: No evaluation results or failures detected: {failures}\")\n",
    "                return None, {}\n",
    "            num_examples_total = sum([evaluate_res.num_examples for _, evaluate_res in results])\n",
    "            if num_examples_total == 0:\n",
    "                logger.warning(f\"Round {server_round}: No evaluation examples available\")\n",
    "                return None, {}\n",
    "            classifier_results = [(r, r.num_examples) for _, r in results if r.metrics.get(\"model_type\") in [\"fraud\", \"budget\"] and r.num_examples > 0]\n",
    "            regressor_results = [(r, r.num_examples) for _, r in results if r.metrics.get(\"model_type\") in [\"expense\", \"forecast\"] and r.num_examples > 0]\n",
    "            metrics_aggregated = {}\n",
    "            loss_aggregated = 0.0\n",
    "            total_examples = 0\n",
    "            for _, res in results:\n",
    "                logger.info(f\"Round {server_round}: Client result - model_type={res.metrics.get('model_type')}, loss={res.loss}, metrics={res.metrics}, examples={res.num_examples}\")\n",
    "            if classifier_results:\n",
    "                classifier_examples = sum([n for _, n in classifier_results])\n",
    "                if classifier_examples > 0:\n",
    "                    classifier_loss = sum([r.loss * n for r, n in classifier_results]) / classifier_examples\n",
    "                    classifier_accuracy = sum([r.metrics.get(\"accuracy\", 0) * n for r, n in classifier_results]) / classifier_examples\n",
    "                    metrics_aggregated[\"accuracy\"] = classifier_accuracy\n",
    "                    loss_aggregated += classifier_loss * classifier_examples\n",
    "                    total_examples += classifier_examples\n",
    "                    logger.info(f\"Round {server_round}: Classifier loss={classifier_loss}, accuracy={classifier_accuracy}, examples={classifier_examples}\")\n",
    "                else:\n",
    "                    logger.warning(f\"Round {server_round}: No valid classifier examples\")\n",
    "            if regressor_results:\n",
    "                regressor_examples = sum([n for _, n in regressor_results])\n",
    "                if regressor_examples > 0:\n",
    "                    regressor_loss = sum([r.loss * n for r, n in regressor_results]) / regressor_examples\n",
    "                    regressor_mse = sum([r.metrics.get(\"mse\", 0) * n for r, n in regressor_results]) / regressor_examples\n",
    "                    metrics_aggregated[\"mse\"] = regressor_mse\n",
    "                    loss_aggregated += regressor_loss * regressor_examples\n",
    "                    total_examples += regressor_examples\n",
    "                    logger.info(f\"Round {server_round}: Regressor loss={regressor_loss}, mse={regressor_mse}, examples={regressor_examples}\")\n",
    "                else:\n",
    "                    logger.warning(f\"Round {server_round}: No valid regressor examples\")\n",
    "            if total_examples > 0:\n",
    "                loss_aggregated /= total_examples\n",
    "            else:\n",
    "                logger.warning(f\"Round {server_round}: No valid examples for loss aggregation\")\n",
    "                return None, metrics_aggregated\n",
    "            logger.info(f\"Round {server_round}: Aggregated evaluation, loss={loss_aggregated}, metrics={metrics_aggregated}\")\n",
    "            return loss_aggregated, metrics_aggregated\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Round {server_round}: Aggregate evaluate failed: {e}\")\n",
    "            return None, {}\n",
    "\n",
    "    def evaluate(self, server_round: int, parameters: Parameters) -> Optional[Tuple[float, Dict]]:\n",
    "        try:\n",
    "            logger.info(f\"Round {server_round}: Performing server-side evaluation\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Round {server_round}: Server-side evaluation failed: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:00:44.053509Z",
     "iopub.status.busy": "2025-04-15T13:00:44.052916Z",
     "iopub.status.idle": "2025-04-15T13:00:44.068902Z",
     "shell.execute_reply": "2025-04-15T13:00:44.068172Z",
     "shell.execute_reply.started": "2025-04-15T13:00:44.053487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Flower client class\n",
    "class FinancialModelClient(fl.client.NumPyClient):\n",
    "    def __init__(self, client_id: int, model_type: str = 'fraud'):\n",
    "        self.client_id = client_id\n",
    "        self.model_type = model_type\n",
    "        try:\n",
    "            df = create_synthetic_data(num_samples=2000)  \n",
    "            df, _ = preprocess_data(df)\n",
    "            logger.info(f\"Client {client_id}: Data loaded\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Client {client_id}: Data loading failed: {e}\")\n",
    "            raise\n",
    "        datasets = prepare_model_datasets(df)\n",
    "        if model_type not in datasets:\n",
    "            logger.error(f\"Client {client_id}: Invalid model type {model_type}, defaulting to 'fraud'\")\n",
    "            self.model_type = 'fraud'\n",
    "            model_type = 'fraud'\n",
    "        X, y = datasets[model_type]\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42 + client_id\n",
    "        )\n",
    "        if model_type == 'fraud':\n",
    "            unique_labels = len(np.unique(self.y_train))\n",
    "            pos_samples = sum(self.y_train == 1)\n",
    "            if unique_labels > 1 and pos_samples >= 3:\n",
    "                try:\n",
    "                    smote = SMOTE(random_state=42 + client_id, k_neighbors=min(3, pos_samples - 1))\n",
    "                    self.X_train, self.y_train = smote.fit_resample(self.X_train, self.y_train)\n",
    "                    logger.info(f\"Client {client_id}: SMOTE applied, {pos_samples} positive samples\")\n",
    "                except ValueError as e:\n",
    "                    logger.warning(f\"Client {client_id}: SMOTE failed, using original data: {e}\")\n",
    "            else:\n",
    "                logger.warning(f\"Client {client_id}: Insufficient fraud samples ({pos_samples}), skipping SMOTE\")\n",
    "        if model_type in ['fraud', 'budget']:\n",
    "            unique_labels = len(np.unique(self.y_train))\n",
    "            if unique_labels < 2:\n",
    "                logger.warning(f\"Client {client_id}: Single-class training data, adjusting labels\")\n",
    "                self.y_train = np.ones(len(self.y_train))  \n",
    "            neg_count = sum(self.y_train == 0)\n",
    "            pos_count = sum(self.y_train != 0)\n",
    "            scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1\n",
    "            self.model = XGBClassifier(\n",
    "                use_label_encoder=False,\n",
    "                eval_metric='logloss',\n",
    "                random_state=42 + client_id,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.1,  \n",
    "                n_estimators=200,   \n",
    "                scale_pos_weight=scale_pos_weight\n",
    "            )\n",
    "            self.is_classifier = True\n",
    "        else:\n",
    "            self.model = XGBRegressor(\n",
    "                random_state=42 + client_id,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.1,\n",
    "                n_estimators=200\n",
    "            )\n",
    "            self.is_classifier = False\n",
    "        self.train_local_model()\n",
    "\n",
    "    def train_local_model(self):\n",
    "        try:\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            logger.info(f\"Client {self.client_id}: Local model trained\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Client {self.client_id}: Training failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_parameters(self, config) -> NDArrays:\n",
    "        try:\n",
    "            model_bytes = pickle.dumps(self.model)\n",
    "            return [np.frombuffer(model_bytes, dtype=np.uint8)]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Client {self.client_id}: Parameter serialization failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def set_parameters(self, parameters: NDArrays):\n",
    "        if not parameters or not parameters[0].size:\n",
    "            logger.warning(f\"Client {self.client_id}: No valid parameters provided\")\n",
    "            return\n",
    "        try:\n",
    "            model_bytes = parameters[0].tobytes()\n",
    "            self.model = pickle.loads(model_bytes)\n",
    "            logger.info(f\"Client {self.client_id}: Parameters updated\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Client {self.client_id}: Parameter deserialization failed: {e}\")\n",
    "\n",
    "    def fit(self, parameters: NDArrays, config: Dict) -> Tuple[NDArrays, int, Dict]:\n",
    "        try:\n",
    "            self.set_parameters(parameters)\n",
    "            self.train_local_model()\n",
    "            updated_parameters = self.get_parameters(config)\n",
    "            if self.is_classifier:\n",
    "                y_pred = self.model.predict(self.X_train)\n",
    "                train_score = float(accuracy_score(self.y_train, y_pred))\n",
    "            else:\n",
    "                y_pred = self.model.predict(self.X_train)\n",
    "                train_score = -float(mean_squared_error(self.y_train, y_pred))\n",
    "            logger.info(f\"Client {self.client_id}: Fit completed with score {train_score}\")\n",
    "            return updated_parameters, len(self.X_train), {\"train_score\": train_score, \"model_type\": self.model_type}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Client {self.client_id}: Fit failed: {e}\")\n",
    "            return [], 0, {\"model_type\": self.model_type}\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: Dict) -> Tuple[float, int, Dict]:\n",
    "        try:\n",
    "            self.set_parameters(parameters)\n",
    "            if self.is_classifier:\n",
    "                if len(np.unique(self.y_val)) < 2:\n",
    "                    logger.warning(f\"Client {self.client_id} ({self.model_type}): Single-class validation data\")\n",
    "                    return 1.0, len(self.X_val), {\"accuracy\": 0.0, \"model_type\": self.model_type}\n",
    "                y_pred = self.model.predict(self.X_val)\n",
    "                loss = 1.0 - accuracy_score(self.y_val, y_pred)\n",
    "                accuracy = float(accuracy_score(self.y_val, y_pred))\n",
    "                metrics = {\"accuracy\": accuracy, \"model_type\": self.model_type}\n",
    "            else:\n",
    "                y_pred = self.model.predict(self.X_val)\n",
    "                loss = float(mean_squared_error(self.y_val, y_pred))\n",
    "                metrics = {\"mse\": loss, \"model_type\": self.model_type}\n",
    "            logger.info(f\"Client {self.client_id} ({self.model_type}): Evaluation - loss={loss}, metrics={metrics}\")\n",
    "            return loss, len(self.X_val), metrics\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Client {self.client_id} ({self.model_type}): Evaluation failed: {e}\")\n",
    "            return float(\"inf\"), 0, {\"model_type\": self.model_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:00:54.993200Z",
     "iopub.status.busy": "2025-04-15T13:00:54.992735Z",
     "iopub.status.idle": "2025-04-15T13:00:54.997396Z",
     "shell.execute_reply": "2025-04-15T13:00:54.996565Z",
     "shell.execute_reply.started": "2025-04-15T13:00:54.993180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define client_fn\n",
    "def client_fn(cid: str) -> fl.client.Client:\n",
    "    try:\n",
    "        client_id = int(cid)\n",
    "        model_types = ['fraud', 'budget', 'expense', 'forecast']\n",
    "        model_type = model_types[client_id % len(model_types)]\n",
    "        logger.info(f\"Creating client {client_id} with model type {model_type}\")\n",
    "        client = FinancialModelClient(client_id, model_type).to_client()\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Client creation failed for CID {cid}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:01:06.394724Z",
     "iopub.status.busy": "2025-04-15T13:01:06.394067Z",
     "iopub.status.idle": "2025-04-15T13:01:06.399072Z",
     "shell.execute_reply": "2025-04-15T13:01:06.398397Z",
     "shell.execute_reply.started": "2025-04-15T13:01:06.394704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main simulation\n",
    "def main_fl():\n",
    "    try:\n",
    "        logger.info(\"Starting federated learning simulation\")\n",
    "        strategy = BestModelStrategy(\n",
    "            min_fit_clients=4,\n",
    "            min_evaluate_clients=4,\n",
    "            min_available_clients=4\n",
    "        )\n",
    "        fl.simulation.start_simulation(\n",
    "            client_fn=client_fn,\n",
    "            num_clients=4,\n",
    "            config=fl.server.ServerConfig(num_rounds=5),\n",
    "            strategy=strategy,\n",
    "            client_resources={\"num_cpus\": 1, \"num_gpus\": 0},\n",
    "            ray_init_args={\"ignore_reinit_error\": True}\n",
    "        )\n",
    "        logger.info(\"Federated learning simulation completed\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Simulation failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:01:15.493739Z",
     "iopub.status.busy": "2025-04-15T13:01:15.493177Z",
     "iopub.status.idle": "2025-04-15T13:02:04.729945Z",
     "shell.execute_reply": "2025-04-15T13:02:04.728852Z",
     "shell.execute_reply.started": "2025-04-15T13:01:15.493718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
      "2025-04-15 13:01:18,698\tINFO worker.py:1852 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:172.19.2.2': 1.0, 'node:__internal_head__': 1.0, 'CPU': 4.0, 'object_store_memory': 9002540236.0, 'memory': 21005927220.0, 'GPU': 2.0, 'accelerator_type:T4': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[36m(pid=247)\u001b[0m 2025-04-15 13:01:21.090943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=247)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=247)\u001b[0m E0000 00:00:1744722081.130184     247 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=247)\u001b[0m E0000 00:00:1744722081.143048     247 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(pid=244)\u001b[0m 2025-04-15 13:01:21.077893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=246)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=246)\u001b[0m E0000 00:00:1744722081.155041     246 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=246)\u001b[0m E0000 00:00:1744722081.167406     246 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:31] WARNING: /workspace/src/learner.cc:742: \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:32] WARNING: /workspace/src/learner.cc:742: \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:35] WARNING: /workspace/src/learner.cc:742: \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:39] WARNING: /workspace/src/learner.cc:742: \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:39] WARNING: /workspace/src/learner.cc:742: \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:46] WARNING: /workspace/src/learner.cc:742: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:01:53] WARNING: /workspace/src/learner.cc:742: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [13:02:00] WARNING: /workspace/src/learner.cc:742: \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m Parameters: { \"scale_pos_weight\" } are not used.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 4 clients (out of 4)\n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=246)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=247)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m         \n",
      "\u001b[36m(ClientAppActor pid=245)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=244)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 4 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 36.71s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.04749999999999998\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04749999999999998\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.04749999999999998\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.04749999999999998\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.04749999999999998\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.9525), (2, 0.9525), (3, 0.9525), (4, 0.9525), (5, 0.9525)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "# Run the simulation\n",
    "main_fl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7150685,
     "sourceId": 11417504,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
